= Exploring Spring Batch Framework
Álvaro López Medina <alopezme@redhat.com>
v1.0, 2023-12
// Metadata
:description: This repository contains an example of how to run Batch processes on OpenShift using Argo Workflows.
:keywords: openshift, red hat, Batch, Argo, workflows, Spring
// Create TOC wherever needed
:toc: macro
:sectanchors:
:sectnumlevels: 2
:sectnums: 
:source-highlighter: pygments
:imagesdir: docs/images
// Start: Enable admonition icons
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
// Icons for GitHub
:yes: :heavy_check_mark:
:no: :x:
endif::[]
ifndef::env-github[]
:icons: font
// Icons not for GitHub
:yes: icon:check[]
:no: icon:times[]
endif::[]
// End: Enable admonition icons


This repository contains an example of how to run Batch processes on OpenShift using Argo Workflows.

// Create the Table of contents here
toc::[]

== Introduction


This demo contains all you need to deploy Argo Workflows to coordinate the deployment and execution of batch processes created using Spring Batch. For that reason, this repository contains the following sections:

* First, a quick mechanism to deploy **ArgoCD**. https://argoproj.github.io/cd[Argo CD] automates the deployment of the desired application states in the specified target environments. We will use it to deploy Argo Workflows and our Spring Batch application.
* Second, **Argo Workflows**. https://argoproj.github.io/workflows[Argo Workflows] is a container-native workflow engine for orchestrating parallel jobs on Kubernetes. We will use it to handle the execution of the batch processes.
* Third, **Spring Batch**. https://spring.io/projects/spring-batch[Spring Batch] is a processing framework designed for robust execution of jobs. We will use it to load data from a CSV file, process it, and store it in a Database deployed on OpenShift.
* Forth, **PostgreSQL** database. https://www.postgresql.org/[PostgreSQL] is a relational database management system (RDBMS) emphasizing extensibility and SQL compliance. We will use it later when we evolve the Spring Batch process to make it more similar to reality, modifying DB real data.

NOTE: All of this will be deployed and automated on OpenShift using the GitOps principles. If you don't have an OpenShift cluster, https://github.com/alvarolop/ocp-installation[check this repo] on how to deploy an OCP cluster on-premise.

TIP: `Data Processing` is one of the https://argoproj.github.io/argo-workflows/use-cases/data-processing/[typical use cases] for Argo Workflows.


== ArgoCD 

There are many ways to install an ArgoCD instance. Among all of them, I've chosen to use https://docs.openshift.com/gitops/1.11/understanding_openshift_gitops/about-redhat-openshift-gitops.html[Red Hat's OpenShift GitOps]. Red Hat OpenShift GitOps is based on the open source project https://argo-cd.readthedocs.io/en/stable/[Argo CD] and provides a similar set of features to what the upstream offers, with additional automation, integration into Red Hat OpenShift Container Platform and the benefits of Red Hat's enterprise support, quality assurance and focus on enterprise security.


The installation of OpenShift GitOps is based on an operator that is installed using the Operator Lifecycle Manager (OLM). To simplify the installation of the operator and the creation of the ArgoCD instance, I've created a simple script that you can run on a clean OCP cluster. This script will install all that you need:

* ArgoCD instance with the correct RBAC.
* Argo Workflows server and controller with RBAC as well as some namespaces to run the Workflows.
* Argo WF workflows to run Spring Batch jobs on OpenShift.
* A PostgreSQL instance for the future. 

.All-in-one script
[source, bash]
----
./argocd/auto-install.sh
----




== Argo Workflows


There are, also, many official ways to deploy Argo Workflows, all of them on https://argoproj.github.io/argo-workflows/installation/[this page of the documentation]. Apart from the quick-start installation, there are two mechanisms: 1) the single-YAML release manifests and 2) the community-maintained Helm Charts. For this exercise, we are going to use the Helm Charts, as it provides more flexibility and adaptability. 

From the basic Helm Chart provided in their https://github.com/argoproj/argo-helm/tree/main/charts/argo-workflows[GitHub repository], I've also added both a Namespace and a Route to make sure that the resources are not deployed in the `default` namespace.

I have created a modified `values.yaml` to customize the Argo Workflows behavior:

* Provide HA configuration, based on the https://argoproj.github.io/argo-workflows/high-availability/[documentation] and the https://github.com/argoproj/argo-helm/blob/main/charts/argo-workflows/ci/ha-values.yaml[Helm Chart example values].
* Expose metrics and collect them using a ServiceMonitor according to the https://argoproj.github.io/argo-workflows/metrics/[documentation]. The Helm chart already takes care of that in these https://github.com/argoproj/argo-helm/blob/main/charts/argo-workflows/ci/enable-metrics-values.yaml[example values].
* Limit the namespaces that the controller monitors to make sure that jobs are not executed in the wrong namespaces.
* Configure the ArgoCD DEX as the SSO identity provider to inherit users and groups from OCP.


As there are some settings not included in the default Helm Chart, I have defined a wrapper chart (`argo-workflows/argo-wf-config`) that defines the official Helm Chart as a dependency. This new Helm Chart does, at least, the following:

* Configures RBAC using a SA for each OCP group, and a RoleBinding or ClusterRoleBinding depending on the need.
* A default namespace to install the server.
* A Route to expose the server, the OCP way.
* A ConsoleLink to simplify accessing the Argo Workflows cluster every time.
* All the resources to deploy a local instance of the DEX server (Still WIP).


NOTE: For general info, I recommend this guide about https://blog.argoproj.io/practical-argo-workflows-hardening-dd8429acc1ce[Argo Workflows Hardening].





== Spring Batch application

The Spring Batch application dubbed *Capitalator* is just a demo application from the https://spring.io/guides/gs/batch-processing/[official guides], which has been adapted to the needs of this demo use case:

* New name of the application.
* Exposing metrics using `micrometer` (Still WIP).
* Option to connect to an external PostgreSQL deployed in another OCP namespace, instead of in-memory HyperSQL DB) (Still WIP).

NOTE: If you are not interested in manual push, just continue to the next section.


=== Manual I: Generate container image locally

A simple Dockerfile is stored in `src/main/docker/Dockerfile.springboot-jar`, and you can manually generate and push the container image to Quay with the following manual steps:


[source, bash]
----
# Generate the Jar file with all the dependencies
mvn clean package

# Add the executable to a container image
podman build -f src/main/docker/Dockerfile.springboot-jar -t spring-boot/spring-batch-capitalator .

# Launch the application
podman run -i --rm spring-boot/spring-batch-capitalator
----


=== Manual II: Push image to Quay

Then, push the image to Quay using the following commands (Previously login to Quay with an authorized account):

[source, bash]
----
# Tag the image to point to your Quay URL
podman tag spring-boot/spring-batch-capitalator quay.io/alopezme/spring-batch-capitalator

# Push image to Quay
podman push quay.io/alopezme/spring-batch-capitalator
----

=== Automated: GitHub Actions

As we don't want to manually execute commands to generate and push a container image, I have automated the Build and Push process with a GH Workflow that is triggered every time a new commit is pushed and affects one of the files of the application itself.

Also, if a new git tag in `semver` format is pushed, it will generate an extra image using that tag as a container tag to the Quay repo.

For this to work, it is necessary to create a Robot Account in Quay with write permissions and create the following two secrets in the Git repository:

* *QUAY_REPO_TOKEN*.
* *QUAY_REPO_USERNAME*.




== CronJobs: Deploy to OpenShift without Argo Workflows

If you don't need any Batch Processing Orchestration, you can use an OpenShift CronJob that will execute the job periodically. For that, you have two options, still using ArgoCD to deploy the resources, or deploy them manually:

[source, bash]
----
# ArgoCD application
oc apply -f argocd/apps/application-capitalator-cronjob.yaml

# Apply resources directly
oc apply -f capitalator-cronjob
----






== PostgreSQL Database

To make the Spring Batch Capitalator example more similar to a real use case, this repository also provides a simple mechanism to deploy a `postgresql` database on a side namespace, so that Capitalator can connect and store the uppercase version of the names. You can deploy the DB either by creating an ArgoCD application or applying the resources directly:

[source, bash]
----
# ArgoCD application
oc apply -f argocd/apps/application-postgresql.yaml

# Apply resources directly
oc apply -f db-postgresql/
----









== Useful resources



